#!/usr/bin/env python
# coding=utf-8
# https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_cli.html
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import sys

from disentanglement_lib.evaluation.metrics.mig import compute_mig
from disentanglement_lib.methods.unsupervised.train import DataModule , PLModel, Iterate
from disentanglement_lib.methods.unsupervised import callbacks
from disentanglement_lib.data.named_data import get_named_ground_truth_data
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
import torch
import os
import argparse
import pathlib
import shutil
import gin
from pytorch_lightning.loggers import WandbLogger, CSVLogger, TensorBoardLogger

from disentanglement_lib.utils.results import save_gin
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--max_steps',type=int,default=1000)
    parser.add_argument('--output_dir',type=str,default='outputs')
    parser.add_argument('-c', '--configs', default=["model.gin"],nargs='+')
    parser.add_argument('--wandb', action='store_true', default=False)
    
    args, unknown = parser.parse_known_args()
        
    for gin_file in args.configs:
        print('load gin config', gin_file)
        gin.parse_config_file(gin_file)
        
    
    if unknown:
        unknown = [i.strip('--') for i in unknown]
        gin.parse_config(unknown)
        
    print(gin.config_str())
    
    CALLBACK_STEPS = args.max_steps//5
    pl_model = PLModel()
    dataset = get_named_ground_truth_data()    
    dl = torch.utils.data.DataLoader(dataset,256,num_workers=4,pin_memory=True, shuffle=True )
    
    
    callbacks_fn = [
        # callbacks.Traversal(CALLBACK_STEPS),
        # callbacks.ShowSamples(CALLBACK_STEPS,dataset),
        ModelCheckpoint(every_n_train_steps=CALLBACK_STEPS), # save last
    ]
    if dataset.supervision: 
        callbacks_fn.append(callbacks.ComputeMetric(CALLBACK_STEPS,compute_mig,dataset))

    if not args.wandb:
        logger = CSVLogger(args.output_dir,name='run')
        
    else:
        logger = WandbLogger(save_dir=args.output_dir,sync_step=False)


    trainer = pl.Trainer(
        logger,
        accelerator='gpu', devices=1,
        max_steps=args.max_steps,
        callbacks=callbacks_fn,
        # enable_progress_bar=False,
        # checkpoint_callback=False,
        weights_summary=None,
    )
    trainer.fit(pl_model, dl)

    # save all config
    for cb in trainer.callbacks:
        if isinstance(cb,ModelCheckpoint): 
            save_path = os.path.join(cb.dirpath,'../')
            save_gin(os.path.join(save_path, "model.gin"))
            print(save_path)
    
    
