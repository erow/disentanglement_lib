#!/usr/bin/env python
# coding=utf-8

# from disentanglement_lib.methods.unsupervised import train
# from disentanglement_lib.evaluation import evaluate
# from disentanglement_lib.methods.unsupervised.train import Train
from disentanglement_lib.config.unsupervised_study_v1.sweep import UnsupervisedStudyV1
import gin
from typing import List, Optional
import pytorch_lightning as pl
import argparse
from pytorch_lightning.core.lightning import LightningModule
import os
import yaml
import gin
from pytorch_lightning.utilities.cli import LightningArgumentParser, LightningCLI

def generate_training_config():
    parser = LightningArgumentParser()
    # add_core_arguments_to_parser
    parser.add_argument(
            "--seed_everything",
            type=Optional[int],
            default=99,
            help="Set to an int to run seed_everything with this value before classes instantiation",
        )
    parser.add_lightning_class_args(pl.Trainer, "trainer")

    """Creates argument links for optimizers and lr_schedulers that specified a link_to"""
    for key, (class_type, link_to) in parser.optimizers_and_lr_schedulers.items():
        if link_to == "AUTOMATIC":
            continue
        if isinstance(class_type, tuple):
            parser.link_arguments(key, link_to)

    args = parser.parse_args()
    dict_args = vars(args)
    print(yaml.dump(dict_args))
    pass
def generate_model_config(model_id):
    from disentanglement_lib.methods.unsupervised import model
    study = UnsupervisedStudyV1()
    bindings, share_conf = study.get_model_config(model_id)
    gin.parse_config(bindings, True)
    return  (gin.config_str())


parser =  argparse.ArgumentParser('dlib_config')
parser.add_argument('--model_id', type=int, default=0)

args = parser.parse_args()

print(generate_model_config(args.model_id))